# -*- coding: utf-8 -*-
"""cleaning dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lxEmc6RrQS-huwM2fPwuSVvttkib31uO

#1.Cleaning Data

##1.1.Downloading Data

* CustomerID: Unique customer ID
* Churn: Churn Flag
* Tenure: Tenure of customer in organization
* PreferredLoginDevice: Preferred login device of customer
* CityTier: City tier
* WarehouseToHome: Distance in between warehouse to home of customer
* PreferredPaymentMode: Preferred payment method of customer
* Gender: Gender of customer
* HourSpendOnApp: Number of hours spend on mobile application or website
* NumberOfDeviceRegistered: Total number of deceives is registered on particular customer
* PreferedOrderCat: Preferred order category of customer in last month
* SatisfactionScore: Satisfactory score of customer on service
* MaritalStatus: Marital status of customer
* NumberOfAddress: Total number of added added on particular customer
* OrderAmountHikeFromlastYear: Percentage increases in order from last year
* CouponUsed: Total number of coupon has been used in last month
* OrderCount: Total number of orders has been places in last month
* DaySinceLastOrder: Day Since last order by customer
* CashbackAmount: Average cashback in last month
"""

import pandas as pd
import gdown

# Extract file ID from the Google Drive link
file_id = "10Sd_PzQNCly7BRT2SjRwCWVlFpgLAfqN"

# Create a direct download URL
url = f"https://drive.google.com/uc?id={file_id}"

# Define the local file path
file_path = "/content/data.xlsx"

# Download the file from Google Drive
gdown.download(url, file_path, quiet=False)

# Read only the "E Comm" sheet from the Excel file
df = pd.read_excel(file_path, sheet_name="E Comm")

# Display the first few rows of the dataset
df.head()

churn_df = df.copy()

"""##1.2.Define Pandas display format"""

pd.set_option("display.float_format", lambda x: "%.2f" % x)
pd.set_option("display.max_rows", 1000)

"""##1.3.Exclude unwanted orders"""

churn_df.head()

churn_df.info()

churn_df[churn_df.duplicated()]

"""There are no duplicate entries."""

churn_df.CustomerID.nunique()

"""##1.4.Handle Missing Values"""

print(churn_df.isnull().sum())

df.describe().transpose()

"""###1.4.1.Separate missing numerical and categorical data

Strategy for Handling Missing Values:

If a column has less than 5% missing values → Fill with median (for numerical) or mode (for categorical).
"""

# Separate numerical and categorical columns
numerical_cols = df.select_dtypes(include=["int64", "float64"]).columns
categorical_cols = df.select_dtypes(include=["object"]).columns

# Check missing values in numerical columns
print("Missing values in numerical columns:")
print(df[numerical_cols].isnull().sum())

print("\nMissing values in categorical columns:")
print(df[categorical_cols].isnull().sum())

"""We don't have missing categorical data, so, we should handle only missing numerical values."""

churn_cleaned = churn_df.copy()

"""The mean is affected by outliers—if there are extremely high or low values, the mean can be skewed significantly.

Median is better when data has outliers or is skewed.
"""

num_cols = ["Tenure", "WarehouseToHome", "HourSpendOnApp",
            "OrderAmountHikeFromlastYear", "CouponUsed",
            "OrderCount", "DaySinceLastOrder"]

for col in num_cols:
    churn_cleaned[col] = churn_cleaned[col].fillna(churn_cleaned[col].median())

churn_cleaned.info()

# Print categorical column names and their value counts
for col in churn_cleaned.select_dtypes(include='object'):
    print(f"{col}\n\nThe values are:\n{churn_cleaned[col].value_counts()}\n")

"""##1.5.Outlier Detection and Removal

We should check numerical columns that represent continuous data, as outliers are more common in these types of features.

✅Numerical Columns to Check for Outliers:

Tenure – Customer’s time with the company (may have unusually high/low values).

WarehouseToHome – Distance to warehouse (possible extreme distances).

HourSpendOnApp – Hours spent on the app (may have unrealistic usage).

OrderAmountHikeFromlastYear – Percentage increase in orders (can have extreme spikes).

CouponUsed – Number of coupons used (some users might abuse coupons).

OrderCount – Number of orders in the last month (potentially unrealistic order numbers).

DaySinceLastOrder – Days since last order (outliers could indicate inactive users).

CashbackAmount – Cashback received (some users may receive exceptionally high amounts).

###1.5.1.Visualization of Outliers Using Boxplots
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set visualization style
sns.set(style="whitegrid")

# List of numerical columns to visualize
outlier_columns = [
    'Tenure', 'WarehouseToHome', 'HourSpendOnApp', 'OrderAmountHikeFromlastYear',
    'CouponUsed', 'OrderCount', 'DaySinceLastOrder', 'CashbackAmount'
]

# Create subplots: 2 rows, 4 columns (for 8 features)
fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
fig.suptitle('Outlier Detection Using Boxplots', fontsize=16)

# Loop through each column and plot boxplot
for i, col in enumerate(outlier_columns):
    row, col_idx = divmod(i, 4)  # Arrange subplots in grid
    sns.boxplot(y=churn_cleaned[col], ax=axes[row, col_idx], color='#1f4d7a')
    axes[row, col_idx].set_title(col)

plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout
plt.show()

"""###1.5.2.Visualization of Outliers Using Histograms"""

# Create subplots for histograms
fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
fig.suptitle('Distribution of Numerical Columns', fontsize=16)

# Loop through each column and plot histogram
for i, col in enumerate(outlier_columns):
    row, col_idx = divmod(i, 4)
    sns.histplot(churn_cleaned[col], bins=30, kde=True, ax=axes[row, col_idx], color='#1f4d7a')
    axes[row, col_idx].set_title(col)

plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

"""###1.5.3.Removing Outliers"""

def remove_outliers(df, columns):
    """
    Removes outliers using the IQR method for specified columns.

    Parameters:
    df (pd.DataFrame): The DataFrame to clean.
    columns (list): List of numerical columns to check for outliers.

    Returns:
    pd.DataFrame: Cleaned DataFrame without outliers.
    """
    df_cleaned = df.copy()  # Create a copy of the dataframe

    for col in columns:
        Q1 = df_cleaned[col].quantile(0.25)  # 25th percentile
        Q3 = df_cleaned[col].quantile(0.75)  # 75th percentile
        IQR = Q3 - Q1  # Interquartile Range

        lower_bound = Q1 - 1.5 * IQR  # Lower bound
        upper_bound = Q3 + 1.5 * IQR  # Upper bound

        # Remove rows with outliers
        df_cleaned = df_cleaned.loc[(df_cleaned[col] >= lower_bound) & (df_cleaned[col] <= upper_bound)]

    return df_cleaned

# List of columns to clean
outlier_columns = [
    'Tenure', 'WarehouseToHome', 'HourSpendOnApp', 'OrderAmountHikeFromlastYear',
    'CouponUsed', 'OrderCount', 'DaySinceLastOrder', 'CashbackAmount'
]

# Apply the function on churn_cl DataFrame
churn_cl = remove_outliers(churn_cleaned, outlier_columns)

# Check the new shape of the dataset
print("Original dataset shape:", churn_cleaned.shape)
print("Cleaned dataset shape:", churn_cl.shape)

import matplotlib.pyplot as plt
import seaborn as sns

# Set visualization style
sns.set(style="whitegrid")

# List of numerical columns to visualize
outlier_columns = [
    'Tenure', 'WarehouseToHome', 'HourSpendOnApp', 'OrderAmountHikeFromlastYear',
    'CouponUsed', 'OrderCount', 'DaySinceLastOrder', 'CashbackAmount'
]

# Create subplots: 2 rows, 4 columns (for 8 features)
fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
fig.suptitle('Outlier Detection Using Boxplots', fontsize=16)

# Loop through each column and plot boxplot
for i, col in enumerate(outlier_columns):
    row, col_idx = divmod(i, 4)  # Arrange subplots in grid
    sns.boxplot(y=churn_cl[col], ax=axes[row, col_idx], color='#1f4d7a')
    axes[row, col_idx].set_title(col)

plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout
plt.show()

churn_cl.info()

churn_cl.shape

churn_cl.head(50)



"""# 1.6 Proceeding without deleting outliers.
## (Work with dataset churn_cleaned)

### 1.6.1 Rename OrderAmountHikeFromlastYear to OrderGrowthFromLastYear
"""

churn_cleaned.rename(columns={'OrderAmountHikeFromlastYear': 'OrderGrowthFromLastYear'}, inplace=True)

"""###1.6.2 In PreferedOrderCat rename 'Mobile' to 'Mobile phone' and 'Grocery' to 'Office supplies'

"""

churn_cleaned['PreferedOrderCat'] = churn_cleaned['PreferedOrderCat'].replace({'Mobile':'Mobile Phone', 'Grocery':'Office supplies'})

#check
churn_cleaned['PreferedOrderCat'].value_counts()

#check
print(churn_cleaned.isna().sum())

#downloading
from google.colab import files

churn_cleaned.to_csv("churn_cleaned.csv", index=False)
files.download("churn_cleaned.csv")

"""###1.6.3 Deleting Rows with Tenure ≥ 50"""

# Remove rows where Tenure is greater than or equal to 50
churn_cl = churn_cleaned[churn_cleaned['Tenure'] < 50]

# Verify the change
print(churn_cl.shape)  # Check new dimensions after filtering

# Select rows where Tenure is greater than or equal to 50
tenure_50_plus = churn_cl[churn_cl['Tenure'] >= 50]

# Display the filtered rows
print(tenure_50_plus)

#downloading
from google.colab import files

churn_cl.to_csv("churn_cl.csv", index=False)
files.download("churn_cl.csv")